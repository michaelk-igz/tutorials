{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model-deployment-with-streaming\"></a>\n",
    "## Model Deployment with Streaming\n",
    "\n",
    "Deploy a model with streaming information. [The demo](model-deployment-with-streaming/0-setup.ipynb) covers the use case of 1<sup>st</sup>-day churn.\n",
    "\n",
    "The importance of 1<sup>st</sup>-day churn prediction:\n",
    "- In some segments of the gaming industry, the average 1st day churn is as high as 70%.\n",
    "- Acquiring new customers is 5x&ndash;25x more expensive than retaining existing ones.\n",
    "- Reducing churn by just 5% can boost profitability by 75%.\n",
    "- Improving retention has a 2x&ndash;4x greater impact on growth than acquisition.\n",
    "- The probability of selling to an existing customer is 60%&ndash;70%, but only 5%&ndash;20% for a prospect.\n",
    "- Churn rate also informs metrics like customer lifetime value (LTV).\n",
    "\n",
    "This demo is comprised of several steps:\n",
    "\n",
    "![Model deployment with streaming Real-time operational Pipeline](../../assets/images/model-deployment-with-streaming.png)\n",
    "\n",
    "While this demo covers the use case of 1<sup>st</sup>-day churn, it is easy to replace the data, related features and training model and reuse the same workflow for different business cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These steps are covered by the following notebooks:\n",
    "\n",
    "- **0. Setup** (this notebook) - Creates the project and the relevant streams.\n",
    "- [**1. Event generator**](1-event-generator.ipynb) â€” Generates events for the training and serving. \n",
    "- [**2. incoming event handler**](2-incoming-event-handler.ipynb) - Receive data from the input. This is a common input stream for all the data. This way, one can easily replace the event source data (in this case we have a data generator) without affecting the rest of this flow.\n",
    "- [**2a. Stream to parquet**](2a-stream-to-parquet.ipynb) - Store all incoming data to parquet files.\n",
    "- [**3a. Enrichment table**](3a-enrichment-table.ipynb) - Create an enrichment table (lookup values).\n",
    "- [**3b. Enrich stream**](3b-enrich-stream.ipynb) - Enrich the stream using the enrichment table.\n",
    "- [**4. Stream to features**](4-stream-to-features.ipynb) - Update aggregation features using the incoming event handler.\n",
    "- [**5. Serving**](5-serving.ipynb) - Serve the model and process the data from the enriched stream and aggregation features.\n",
    "\n",
    "This demo comes with a pre-trained model using the base features, enrichment data and derived features, calculated using the same generated data. You can retrain the model or train a new model by opening and running the  [**4b. optional training notebook**](4b.-optional-training.ipynb). You will need to ensure enough data is collected via the streams to the data storage in order to train a new model.\n",
    "\n",
    "## About this demo\n",
    "\n",
    "### Input Data\n",
    "\n",
    "The event generator ([1-event-generator.ipynb](1-event-generator.ipynb)) creates the following events: `new_registration`, `new_purchases`, `new_bet` and `new_win` with the following data:\n",
    "\n",
    "| new_registration |   | new_purchases |   | new_bet    |   | new_win    |\n",
    "|------------------|---|---------------|---|------------|---|------------|\n",
    "| user_id          |   | user_id       |   | user_id    |   | user_id    |\n",
    "| event_type       |   | event_type    |   | event_type |   | event_type |\n",
    "| event_time       |   | event_time    |   | event_time |   | event_time |\n",
    "| name             |   | amount        |   | bet_amount |   | win_amount |\n",
    "| date_of_birth    |   |               |   |            |   |            |\n",
    "| street_address   |   |               |   |            |   |            |\n",
    "| city             |   |               |   |            |   |            |\n",
    "| country          |   |               |   |            |   |            |\n",
    "| postcode         |   |               |   |            |   |            |\n",
    "| affiliate_url    |   |               |   |            |   |            |\n",
    "| campaign         |   |               |   |            |   |            |\n",
    "\n",
    "Furthermore, `new_registration` includes a `label` column to indicate whether or not the user has churned (1 for churned and 0 for not)\n",
    "\n",
    "## Enrichment\n",
    "\n",
    "The enrichment table ([3a-enrichment-table.ipynb](3a-enrichment-table.ipynb)) contains a lookup of postcode and returns a socioeconomic index (`socioeconomic_idx`). The enriched stream contains the original data and the enriched data.\n",
    "\n",
    "## Feature calculation\n",
    "\n",
    "During the feature calculation ([4-stream-to-features.ipynb](4-stream-to-features.ipynb)), we calculate sum, mean, count and variance for the 3 amount fields (`amount`, `bet_amount` and `win_amount` for `new_purchases`, `new_bet` and `new_win` respectively). This results with the following list of fields:\n",
    "\n",
    "- purchase_sum\n",
    "- purchase_mean\n",
    "- purchase_count\n",
    "- purchase_var\n",
    "- bet_sum\n",
    "- bet_mean\n",
    "- bet_count\n",
    "- bet_var\n",
    "- win_sum\n",
    "- win_mean\n",
    "- win_count\n",
    "- win_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"gs-mlrun-install\"></a>The tutorial uses MLRun to create a project, implement and execute an ML pipeline, and track the execution.\n",
    "(For more information about MLRun, see Step 1.)\n",
    "To use MLRun, you must first ensure that it's installed and running as a service on your platform cluster.\n",
    "Look for an `mlrun` service on the **Services** page of the platform dashboard.\n",
    "For more information and additional assistance, contact the Iguazio [support team](mailto:support@iguazio.com).\n",
    "\n",
    "To use MLRun from Jupyter Notebook, you need to run the following code to install the `mlrun` Python package.\n",
    "This needs to be done only once per Jupyter Notebook service.\n",
    "> **Note:** You must **restart the Jupyter kernel** to complete the installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already installed: mlrun\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "import IPython\n",
    "\n",
    "required = {'mlrun'}\n",
    "installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "missing = required - installed\n",
    "previously_installed = required.intersection(installed)\n",
    "\n",
    "if missing:\n",
    "    print(f'Installing {\",\".join(missing)}')\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing], stdout=subprocess.DEVNULL)\n",
    "    print('Restarting kernel')\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel\n",
    "if previously_installed:\n",
    "    print(f'Already installed: {\",\".join(previously_installed)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration below is shared across the notebooks. Change the values in this subsection if you would like different configuration settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projects in the platform are used to package multiple functions, workflows, and artifacts. Set here the project base name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_BASE_NAME = \"model-deployment-with-streaming\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data in the platform is stored in user-defined data containers. In this case we use the predefined \"users\" container. For more information refer to [Data containers, collections, and objects documentation](https://www.iguazio.com/docs/latest-release/concepts/containers-collections-objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTAINER = 'users'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data path where to store stream data and kv tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv, path\n",
    "\n",
    "V3IO_USERNAME = getenv('V3IO_USERNAME')\n",
    "DATA_PATH = path.join(V3IO_USERNAME, 'examples',PROJECT_BASE_NAME, 'data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the different stream information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urljoin\n",
    "WEB_API = \"http://v3io-webapi:8081\"\n",
    "WEB_API_USERS = urljoin(WEB_API, CONTAINER)\n",
    "STREAM_CONFIGS = {'generated-stream': {\n",
    "                        'path': path.join(DATA_PATH, 'generated-stream'),\n",
    "                        'shard_count': 8},\n",
    "                  'incoming-events-stream': {\n",
    "                        'path': path.join(DATA_PATH, 'incoming-events-stream'),\n",
    "                        'shard_count': 8\n",
    "                  },\n",
    "                  'enriched-events-stream': {\n",
    "                        'path': path.join(DATA_PATH, 'enriched-events-stream'),\n",
    "                        'shard_count': 8\n",
    "                  },\n",
    "                  'serving-stream': {\n",
    "                        'path': path.join(DATA_PATH, 'serving-stream'),\n",
    "                        'shard_count': 8\n",
    "                  },\n",
    "                  'inference-stream': {\n",
    "                        'path': path.join(DATA_PATH, 'inference-stream'),\n",
    "                        'shard_count': 8\n",
    "                  }\n",
    "                 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we stream data, we associate the records with a specific partition key to ensure that similar records are assigned to the same shard. For more information, see the [stream sharding and partitioning description](https://www.iguazio.com/docs/latest-release/concepts/streams/#stream-sharding-and-partitioning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARTITION_ATTR = \"user_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target path to store the raw data as parquet files.\n",
    "The parquet files will be written via file mount, hence we configure the path to start with '/User' which will be mounted to our home dir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARQUET_TARGET_PATH = path.join(DATA_PATH.replace(V3IO_USERNAME, '/User'),  'events-pq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target path to store the enrichment table (a key-value table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENRICHMENT_TABLE_PATH = path.join(DATA_PATH, 'enrichment-table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target path to store the calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_TABLE_PATH = path.join(DATA_PATH, 'feature-table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create V3IO Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataplane client you can manipulate data in the platform's multi-model data layer, including:\n",
    "* Objects\n",
    "* Key-values (NoSQL)\n",
    "* Streams\n",
    "* Containers\n",
    "\n",
    "Under the hood, the client connects through the platform's web API (https://www.iguazio.com/docs/reference/latest-release/api-reference/web-apis/) and wraps each low level API with an interface. Calls are blocking, but you can use the batching interface to send multiple requests in parallel for greater performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v3io.dataplane\n",
    "v3io_client = v3io.dataplane.Client(endpoint=WEB_API,\n",
    "                                    access_key=getenv('V3IO_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage Streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete all streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleanup previous streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delete Stream call for stream generated-stream returned with status 404, and content: {\n",
      "\t\"ErrorCode\": -2,\n",
      "\t\"ErrorMessage\": \"No such file or directory\"\n",
      "}\n",
      "Delete Stream call for stream incoming-events-stream returned with status 404, and content: {\n",
      "\t\"ErrorCode\": -2,\n",
      "\t\"ErrorMessage\": \"No such file or directory\"\n",
      "}\n",
      "Delete Stream call for stream enriched-events-stream returned with status 404, and content: {\n",
      "\t\"ErrorCode\": -2,\n",
      "\t\"ErrorMessage\": \"No such file or directory\"\n",
      "}\n",
      "Delete Stream call for stream serving-stream returned with status 404, and content: {\n",
      "\t\"ErrorCode\": -2,\n",
      "\t\"ErrorMessage\": \"No such file or directory\"\n",
      "}\n",
      "Delete Stream call for stream inference-stream returned with status 404, and content: {\n",
      "\t\"ErrorCode\": -2,\n",
      "\t\"ErrorMessage\": \"No such file or directory\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for stream_name, stream_config in STREAM_CONFIGS.items():\n",
    "    resp = v3io_client.delete_stream(container=CONTAINER, path=stream_config['path'], \n",
    "                                     raise_for_status=v3io.dataplane.RaiseForStatus.never)\n",
    "    print(f'Delete Stream call for stream {stream_name} returned with status {resp.status_code}, and content: {resp.body.decode(\"utf-8\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create all streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iguazio/examples/model-deployment-with-streaming/data/generated-stream\n",
      "Create Stream call for stream generated-stream returned with status 204, and content: \n",
      "iguazio/examples/model-deployment-with-streaming/data/incoming-events-stream\n",
      "Create Stream call for stream incoming-events-stream returned with status 204, and content: \n",
      "iguazio/examples/model-deployment-with-streaming/data/enriched-events-stream\n",
      "Create Stream call for stream enriched-events-stream returned with status 204, and content: \n",
      "iguazio/examples/model-deployment-with-streaming/data/serving-stream\n",
      "Create Stream call for stream serving-stream returned with status 204, and content: \n",
      "iguazio/examples/model-deployment-with-streaming/data/inference-stream\n",
      "Create Stream call for stream inference-stream returned with status 204, and content: \n"
     ]
    }
   ],
   "source": [
    "for stream_name, stream_config in STREAM_CONFIGS.items():\n",
    "    print(stream_config['path'])\n",
    "    resp = v3io_client.create_stream(container=CONTAINER,\n",
    "                                     path=stream_config['path'],\n",
    "                                     shard_count=stream_config['shard_count'],\n",
    "                                     raise_for_status=v3io.dataplane.RaiseForStatus.never)\n",
    "    print(f'Create Stream call for stream {stream_name} returned with status {resp.status_code}, and content: {resp.body.decode(\"utf-8\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up MLRun Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projects are created by using the `new_project` MLRun method, which receives the following parameters:\n",
    "\n",
    "- **`name`** (Required) &mdash; the project name.\n",
    "- **`context`** &mdash; the path to a local project directory (the project's context directory).\n",
    "  The project directory contains a project-configuration file (default: **project.yaml**), which defines the project, and additional generated Python code.\n",
    "  The project file is created when you save your project (using the `save` MLRun project method), as demonstrated in Step 6.\n",
    "- **`functions`** &mdash; a list of functions objects or links to function code or objects.\n",
    "- **`init_git`** &mdash; set to `True` to perform Git initialization of the project directory (`context`).\n",
    "  > **Note:** It's customary to store project code and definitions in a Git repository.\n",
    "\n",
    "Projects are visible in the MLRun dashboard only after they're saved to the MLRun database, which happens whenever you run code for a project.\n",
    "\n",
    "The following code creates a project using the `PROJECT_BASE_NAME`, concatenated with your current running username in the platform (**&lt;V3IO_USERNAME&gt;**), and sets the project directory to a **conf** directory in the current demo directory (**/User/demos/model-deployment-with-streaming/conf**).\n",
    "\n",
    "> **Note:** Platform projects are shared among all users of the parent tenant, to facilitate collaboration. Therefore,\n",
    ">\n",
    "> - Synchronize your projects execution with other users on your platform cluster, as needed, or use unique project names to avoid conflicts.\n",
    ">   You can easily change the default project name for this tutorial by changing the definition of the `PROJECT_BASE_NAME` variable, defined in the beginning of the notebook.\n",
    "> - Don't include in your project proprietary information that you don't want to expose to other users.\n",
    ">   Note that while projects are a useful tool, you can easily develop and run code in the platform without using projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project path: /User/work/tutorials/demos/model-deployment-with-streaming/conf\n",
      "Project name: model-deployment-with-streaming-iguazio\n"
     ]
    }
   ],
   "source": [
    "from mlrun import new_project\n",
    "\n",
    "project_name = '-'.join(filter(None, [PROJECT_BASE_NAME, getenv('V3IO_USERNAME', None)]))\n",
    "project_path = path.abspath('conf')\n",
    "project = new_project(project_name, project_path, init_git=True)\n",
    "\n",
    "print(f'Project path: {project_path}\\nProject name: {project_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MLRun](https://github.com/mlrun/mlrun) is a generic and convenient mechanism for data scientists and software developers to describe and run tasks related to machine learning in various, scalable runtime environments and ML pipelines while automatically tracking executed code, metadata, inputs, and outputs.\n",
    "MLRun integrates with the Nuclio serverless framework and with the Kubeflow Pipelines framework for running ML pipelines.\n",
    "The demo uses MLRun to create a project, run Nuclio serverless functions, as well as run the model training.\n",
    "Before running your code, you need to set some MLRun configurations:\n",
    "\n",
    "- <a id=\"gs-mlrun-config-artifcats-path\"></a>**Artifacts path** &mdash; the location for storing versioned data artifacts (such as files, objects, data sets, and models) that are produced or consumed by functions, runs, and workflows.\n",
    "  The path can be defined either as a local directory path or as a URL (of the format `s3://*`, `v3io://*`, etc.).\n",
    "  You can set the artifacts path either by defining an `MLRUN_ARTIFACT_PATH` environment variable (which applies globally throughout the current environment) or as part of the MLRun configuration.\n",
    " \n",
    "  If the target directory doesn't exist, MLRun creates it.\n",
    "  You can use the notation `{{run.uid}}` in the path to signify the current run ID.\n",
    "  For pipelines, you can use the notation `{{workflow.uid}}` to signify the workflow ID.\n",
    "  This allows you to create a unique artifacts directory for each executed job or workflow.\n",
    "\n",
    "  After you run an MLRun job, the artifacts directory might contain one or more of the following directories:\n",
    " \n",
    "  - **plots** &mdash; a directory for storing images, figures, and plotlines.\n",
    "  - **models** &mdash; a directory for storing all trained models.\n",
    "  - **data** &mdash; a directory for storing any other type of data artifact, such as data sets.\n",
    "\n",
    "The following code sets the artifacts path to a **artifacts** directory within the tutorial directory (**/User/demos/model-deployment-with-streaming/artifacts**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts path: /User/work/tutorials/demos/model-deployment-with-streaming/artifacts\n",
      "MLRun DB path: http://mlrun-api:8080\n"
     ]
    }
   ],
   "source": [
    "from mlrun import mlconf\n",
    "\n",
    "# Target location for storing pipeline artifacts\n",
    "project.artifact_path = path.abspath('artifacts')\n",
    "# MLRun DB path or API service URL\n",
    "#mlconf.dbpath = mlconf.dbpath or 'http://mlrun-api:8080'\n",
    "\n",
    "print(f'Artifacts path: {project.artifact_path}\\nMLRun DB path: {mlconf.dbpath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the configuration defined in this notebook in the project `params`. We will use these values in subsequent notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.params['PROJECT_BASE_NAME'] = PROJECT_BASE_NAME\n",
    "project.params['STREAM_CONFIGS'] = STREAM_CONFIGS\n",
    "project.params['CONTAINER'] = CONTAINER\n",
    "project.params['WEB_API'] = WEB_API\n",
    "project.params['WEB_API_USERS'] = WEB_API_USERS\n",
    "project.params['PARTITION_ATTR'] = PARTITION_ATTR\n",
    "project.params['PARQUET_TARGET_PATH'] = PARQUET_TARGET_PATH\n",
    "project.params['ENRICHMENT_TABLE_PATH'] = ENRICHMENT_TABLE_PATH\n",
    "project.params['FEATURE_TABLE_PATH'] = FEATURE_TABLE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "CONTAINER": "users",
       "ENRICHMENT_TABLE_PATH": "iguazio/examples/model-deployment-with-streaming/data/enrichment-table",
       "FEATURE_TABLE_PATH": "iguazio/examples/model-deployment-with-streaming/data/feature-table",
       "PARQUET_TARGET_PATH": "/User/examples/model-deployment-with-streaming/data/events-pq",
       "PARTITION_ATTR": "user_id",
       "PROJECT_BASE_NAME": "model-deployment-with-streaming",
       "STREAM_CONFIGS": {
        "enriched-events-stream": {
         "path": "iguazio/examples/model-deployment-with-streaming/data/enriched-events-stream",
         "shard_count": 8
        },
        "generated-stream": {
         "path": "iguazio/examples/model-deployment-with-streaming/data/generated-stream",
         "shard_count": 8
        },
        "incoming-events-stream": {
         "path": "iguazio/examples/model-deployment-with-streaming/data/incoming-events-stream",
         "shard_count": 8
        },
        "inference-stream": {
         "path": "iguazio/examples/model-deployment-with-streaming/data/inference-stream",
         "shard_count": 8
        },
        "serving-stream": {
         "path": "iguazio/examples/model-deployment-with-streaming/data/serving-stream",
         "shard_count": 8
        }
       },
       "WEB_API": "http://v3io-webapi:8081",
       "WEB_API_USERS": "http://v3io-webapi:8081/users"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "root"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, JSON\n",
    "display(JSON(project.params, expanded=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "project.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to [**1-event-generator.ipynb**](1-event-generator.ipynb) to generates events for the training and serving"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}