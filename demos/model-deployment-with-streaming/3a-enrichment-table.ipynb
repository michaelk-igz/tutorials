{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3a. Enrichment Table\n",
    "  --------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the enrichment table that contains a lookup of postcode and returns a socioeconomic index (`socioeconomic_idx`). The enriched stream contains the original data and the enriched data.\n",
    "\n",
    "This demonstrates a simple way of using V3IO Key-value (KV) to store lookup data.\n",
    "\n",
    "The data is stored to `/User/examples/model-deployment-with-streaming/data/enrichment-table`. You can create similar enrichments using the same method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model deployment with streaming Real-time operational Pipeline](../../assets/images/model-deployment-with-streaming.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlrun import load_project\n",
    "from os import path\n",
    "\n",
    "project_path = path.abspath('conf')\n",
    "project = load_project(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container: users\n",
      "Enrichment table path: iguazio/examples/model-deployment-with-streaming/data/enrichment-table\n"
     ]
    }
   ],
   "source": [
    "container = project.params.get('CONTAINER')\n",
    "enrichment_table_path = project.params.get('ENRICHMENT_TABLE_PATH')\n",
    "print(f'Container: {container}\\nEnrichment table path: {enrichment_table_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create V3IO Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the dataplane client you can manipulate data in the platform's multi-model data layer, including:\n",
    "* Objects\n",
    "* Key-values (NoSQL)\n",
    "* Streams\n",
    "* Containers\n",
    "\n",
    "Under the hood, the client connects through the platform's web API (https://www.iguazio.com/docs/reference/latest-release/api-reference/web-apis/) and wraps each low level API with an interface. Calls are blocking, but you can use the batching interface to send multiple requests in parallel for greater performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import v3io.dataplane\n",
    "from os import getenv\n",
    "v3io_client = v3io.dataplane.Client(endpoint=project.params.get('WEB_API'),\n",
    "                                    access_key=getenv('V3IO_ACCESS_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create enrichment table\n",
    "____________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create enrichment table where the key is postal-code and the value is the socioeconomic index at the area.\n",
    "\n",
    "To get the highest possible throughput, we can send many requests towards the data layer and wait for all the responses to arrive (rather than send each request and wait for the response). The SDK supports this through batching. Any API call can be made through the client's built in `batch` object. The API call receives the exact same arguments it would normally receive (except for `raise_for_status`), and does not block until the response arrives. To wait for all pending responses, call `wait()` on the `batch` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "for postcode in range(10000,99999):\n",
    "    remainder = postcode % 3\n",
    "    if remainder == 0:\n",
    "        idx = randint(3,5)\n",
    "    elif remainder == 1:\n",
    "        idx = randint(1,3)\n",
    "    else:\n",
    "        idx = randint(5,7)\n",
    "\n",
    "    attr = {'postcode': postcode ,'socioeconomic_idx': idx}\n",
    "    v3io_client.batch.put_item(container=container,\n",
    "                               path=path.join(enrichment_table_path, str(postcode)),\n",
    "                               attributes=attr)\n",
    "\n",
    "responses = v3io_client.batch.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The looped `put_item` interface above will send all `put item` requests to the data layer in parallel. When `wait` is called, it will block until either all responses arrive (in which case it will return a `Responses` object, containing the `responses` of each call) or an error occurs - in which case an exception is thrown. You can pass `raise_for_status` to `wait`, and it behaves as explained above.\n",
    "\n",
    "> Note: The `batch` object is stateful, so you can only create one batch at a time. However, you can create multiple parallel batches yourself through the client's `create_batch()` interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue to [**3b-enrich-stream.ipynb**](3b-enrich-stream.ipynb) to enrich the stream using the enrichment table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
